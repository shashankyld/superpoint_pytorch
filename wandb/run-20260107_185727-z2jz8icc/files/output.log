Ready. Total batches: 3125. Saving every 312 batches.
Epoch 1:   0%|                                                   | 0/3125 [00:01<?, ?it/s]
Traceback (most recent call last):
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/train_magicpoint.py", line 167, in <module>
    train()
    ~~~~~^^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/train_magicpoint.py", line 130, in train
    loss, det_loss, _ = criterion(
                        ~~~~~~~~~^
        outputs={'logits': logits},
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
        targets={'keypoints': pts_aug}
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/src/superpoint/training/losses.py", line 73, in forward
    det_loss = self.detector_loss(outputs['logits'], targets['keypoints'])
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/src/superpoint/training/losses.py", line 42, in forward
    return self.cross_entropy(logits, labels)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/modules/loss.py", line 1385, in forward
    return F.cross_entropy(
           ~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<4 lines>...
        label_smoothing=self.label_smoothing,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/shashank/Documents/UniBonn/grad/superpoint_pytorch/.venv/lib/python3.13/site-packages/torch/nn/functional.py", line 3458, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        input,
        ^^^^^^
    ...<4 lines>...
        label_smoothing,
        ^^^^^^^^^^^^^^^^
    )
    ^
RuntimeError: Expected all tensors to be on the same device, but got weight is on cpu, different from other tensors on cuda:0 (when checking argument in method wrapper_CUDA__nll_loss2d_forward)
